{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2c4248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "41571ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df = pd.read_table('human_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f59aaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  class\n",
       "0  ATGCCCCAACTAAATACTACCGTATGGCCCACCATAATTACCCCCA...      4\n",
       "1  ATGAACGAAAATCTGTTCGCTTCATTCATTGCCCCCACAATCCTAG...      4\n",
       "2  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
       "3  ATGTGTGGCATTTGGGCGCTGTTTGGCAGTGATGATTGCCTTTCTG...      3\n",
       "4  ATGCAACAGCATTTTGAATTTGAATACCAGACCAAAGTGGATGGTG...      3"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a882244",
   "metadata": {},
   "source": [
    "Treating DNA sequence as a \"language \" otherwise known as k-mer counting"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49f806f4",
   "metadata": {},
   "source": [
    "Defining a function to collect all possible overlapping k-mers of a specified length from any sequence string.  \n",
    "We basically apply the k-mers to the complere sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e1cf051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default size 6 \n",
    "def getkmers(sequence, size = 6):\n",
    "    return [sequence[x: x+size].lower() for x in range(len(sequence) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "93438c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_df['words'] = human_df.apply(lambda x: getkmers(x['sequence']), axis = 1)\n",
    "human_df = human_df.drop('sequence' , axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0bfd5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgccc, tgcccc, gcccca, ccccaa, cccaac, ccaac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>[atgaac, tgaacg, gaacga, aacgaa, acgaaa, cgaaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[atgcaa, tgcaac, gcaaca, caacag, aacagc, acagc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              words\n",
       "0      4  [atgccc, tgcccc, gcccca, ccccaa, cccaac, ccaac...\n",
       "1      4  [atgaac, tgaacg, gaacga, aacgaa, acgaaa, cgaaa...\n",
       "2      3  [atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...\n",
       "3      3  [atgtgt, tgtgtg, gtgtgg, tgtggc, gtggca, tggca...\n",
       "4      3  [atgcaa, tgcaac, gcaaca, caacag, aacagc, acagc..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce59d5a5",
   "metadata": {},
   "source": [
    "Now convert the list of K-mers for each gene into string sentences of words that the count vectorizer can use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4581fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_text = list(human_df['words'])\n",
    "for item in range(len(human_text)):\n",
    "    human_text[item] = ' '.join(human_text[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7b78e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = human_df.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "366d3f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atgccc tgcccc gcccca ccccaa cccaac ccaact caacta aactaa actaaa ctaaat taaata aaatac aatact atacta tactac actacc ctaccg taccgt accgta ccgtat cgtatg gtatgg tatggc atggcc tggccc ggccca gcccac cccacc ccacca caccat accata ccataa cataat ataatt taatta aattac attacc ttaccc tacccc accccc ccccca ccccat cccata ccatac catact atactc tactcc actcct ctcctt tcctta ccttac cttaca ttacac tacact acacta cactat actatt ctattc tattcc attcct ttcctc tcctca cctcat ctcatc tcatca catcac atcacc tcaccc caccca acccaa cccaac ccaact caacta aactaa actaaa ctaaaa taaaaa aaaaat aaaata aaatat aatatt atatta tattaa attaaa ttaaac taaaca aaacac aacaca acacaa cacaaa acaaac caaact aaacta aactac actacc ctacca taccac accacc ccacct caccta acctac cctacc ctacct tacctc acctcc cctccc ctccct tccctc ccctca cctcac ctcacc tcacca caccaa accaaa ccaaag caaagc aaagcc aagccc agccca gcccat cccata ccataa cataaa ataaaa taaaaa aaaaat aaaata aaataa aataaa ataaaa taaaaa aaaaaa aaaaat aaaatt aaatta aattat attata ttataa tataac ataaca taacaa aacaaa acaaac caaacc aaaccc aaccct accctg ccctga cctgag ctgaga tgagaa gagaac agaacc gaacca aaccaa accaaa ccaaaa caaaat aaaatg aaatga aatgaa atgaac tgaacg gaacga aacgaa acgaaa cgaaaa gaaaat aaaatc aaatct aatctg atctgt tctgtt ctgttc tgttcg gttcgc ttcgct tcgctt cgcttc gcttca cttcat ttcatt tcattc cattca attcat ttcatt tcattg cattgc attgcc ttgccc tgcccc gccccc ccccca ccccac cccaca ccacaa cacaat acaatc caatcc aatcct atccta tcctag\n"
     ]
    }
   ],
   "source": [
    "print(human_text[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f41d36ba",
   "metadata": {},
   "source": [
    "Now we will apply the BAG of WORDS using COuntVectorizer using NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83ac6a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(ngram_range = (4,4))\n",
    "x = cv.fit_transform(human_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3cb6935c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 232414)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4cdbbdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     531\n",
       "1     534\n",
       "2     349\n",
       "3     672\n",
       "4     711\n",
       "5     240\n",
       "6    1343\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_df['class'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16fdaf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4380x232414 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5406441 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7114e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y ,test_size=0.2 , random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a9fac03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4380, 232414) (3504, 232414) (876, 232414)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape , x_train.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b7d6fbb",
   "metadata": {},
   "source": [
    "A multinomial naive Bayes classifier will be created. I previsusly did some parameter tuning and found the ngram size of 4 (reflected in the CountVectorizer() instance ) and a model aplha of 0.1 did the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "60a5f1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha = 0.1)\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "300d2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "959f4b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix \n",
      "\n",
      "Predicted    0   1   2    3    4   5    6\n",
      "Actual                                   \n",
      "0          108   0   0    0    0   0    4\n",
      "1            0  96   0    0    0   0    0\n",
      "2            0   0  60    1    0   0    2\n",
      "3            0   0   0  129    0   0    1\n",
      "4            1   0   0    0  124   0    2\n",
      "5            2   0   0    0    0  49    2\n",
      "6            0   0   1    0    0   0  294\n",
      " Accuravy = 0.982 \n",
      " precision = 0.982 \n",
      " recall = 0.982 \n",
      " f1 = 0.982\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score , f1_score, precision_score, recall_score\n",
    "\n",
    "print('Confusion Matrix \\n')\n",
    "print(pd.crosstab(pd.Series(y_test, name= 'Actual'), pd.Series(y_pred, name='Predicted')))\n",
    "\n",
    "def get_metrics(y_test,y_predicted):\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    precision = precision_score(y_test, y_predicted, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
    "    f1 =f1_score(y_test, y_predicted, average = 'weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
    "\n",
    "print(\" Accuravy = %.3f \\n precision = %.3f \\n recall = %.3f \\n f1 = %.3f\" % (accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f9a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
